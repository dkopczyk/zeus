"""Legacy schedulers that probably don't even work."""


# class ExhaustiveSolver(PowerStateSchedulerV2):
#     """Frequency scheduler that tries out every configuration."""
#
#     def __init__(
#         self,
#         rank_infos: list[RankInfo],
#         perseus_settings: PerseusSettings,
#         prof_csv: str,
#         power_states: list[int],
#         allowed_slowdown: float,
#         prune_slower: bool = True,
#     ) -> None:
#         """Initialize the scheduler.
#
#         Args:
#             prof_csv: Path to the CSV file generated by `InstructionProfiler`.
#             power_states: The list of power states to use as the domain of optimization.
#             allowed_slowdown: How many percents (%) of slowdown is allowed.
#             prune_slower: Whether to prune power state configurations that are slower
#                 than one that exceeded the deadline previously. Here, config a is slower
#                 than config b when all of a's power states are smaller than or equal to
#                 b's corresponding power states.
#         """
#         super().__init__(rank_infos, perseus_settings)
#
#         # Sanity check.
#         for power_state in power_states:
#             if power_state not in self.power_state_range:
#                 raise ValueError(
#                     f"Power state {power_state} is not supported by your device."
#                 )
#
#         self.proc_csv = prof_csv
#         self.power_states = list(sorted(power_states, reverse=True))
#         self.allowed_slowdown = allowed_slowdown
#         self.prune_slower = prune_slower
#
#         self._df = pd.read_csv(prof_csv)
#
#         # self._header: list[str] = []
#         # self._estimated: list[tuple] = []
#
#     @cached_property
#     def _inst_time(self) -> list[dict[PipeInstruction, dict[int, float]]]:
#         inst_time = []
#         for stage_id in range(self.job_info.pp_degree):
#             mdf = (
#                 self._df.loc[self._df.stage == stage_id]
#                 .drop("stage", axis=1)
#                 .set_index(["instruction", "frequency"])[["time"]]
#             )
#             inst_time.append(
#                 {
#                     level: mdf.xs(level).to_dict()["time"]
#                     for level in mdf.index.levels[0]
#                 }
#             )
#         return inst_time
#
#     @cached_property
#     def _inst_energy(self) -> list[dict[PipeInstruction, dict[int, float]]]:
#         inst_energy = []
#         for stage_id in range(self.job_info.pp_degree):
#             mdf = (
#                 self._df.loc[self._df.stage == stage_id]
#                 .drop("stage", axis=1)
#                 .set_index(["instruction", "frequency"])[["energy"]]
#             )
#             inst_energy.append(
#                 {
#                     level: mdf.xs(level).to_dict()["energy"]
#                     for level in mdf.index.levels[0]
#                 }
#             )
#         return inst_energy
#
#     def _run(self) -> Generator[list[PowerStateSchedule], list[ProfilingResult], None]:
#         # Maps instructions that we intend to schedule power states for to their
#         # corresponding instruction class in Rene.
#         instruction_map: dict[PipeInstruction, Type[rene.Instruction]] = {
#             PipeInstruction.FORWARD: rene.Forward,
#             PipeInstruction.BACKWARD: rene.Backward,
#         }
#
#         # Instructions for each stage in the reported pipeline schedule that we
#         # intend to schedule power states for.
#         perseus_insts = [
#             list(filter(instruction_map.get, rank_info.pipe_schedule))
#             for rank_info in self.rank_infos
#         ]
#         reported_num_insts = sum(len(insts) for insts in perseus_insts)
#
#         # First run a step with the max power state config.
#         max_ps = max(self.power_states)
#         max_ps_config: list[list[int]] = (
#             np.array(tuple(max_ps for _ in range(reported_num_insts)))
#             .reshape(self.job_info.pp_degree, -1)
#             .tolist()
#         )
#
#         optimal_ps_config = self._compute_solution()
#
#         def config_to_schedule(config: list[list[int]]) -> list[PowerStateSchedule]:
#             schedules = []
#             for stage_id in range(self.job_info.pp_degree):
#                 schedule = []
#                 config_iter = iter(config[stage_id])
#                 power_state = config[stage_id][0]
#                 for inst in self.rank_infos[stage_id].pipe_schedule:
#                     if inst in [PipeInstruction.FORWARD, PipeInstruction.BACKWARD]:
#                         power_state = next(config_iter)
#                     schedule.append(power_state)
#                 schedules.append(
#                     PowerStateSchedule(rank=stage_id, power_states=schedule)
#                 )
#             return schedules
#
#         _ = yield config_to_schedule(max_ps_config)
#
#         _ = yield config_to_schedule(optimal_ps_config)
#
#     def _compute_solution(self) -> list[list[int]]:
#         # Maps instructions that we intend to schedule power states for to their
#         # corresponding instruction class in Rene.
#         instruction_map: dict[PipeInstruction, Type[rene.Instruction]] = {
#             PipeInstruction.FORWARD: rene.Forward,
#             PipeInstruction.BACKWARD: rene.Backward,
#         }
#
#         # Instructions for each stage in the reported pipeline schedule that we
#         # intend to schedule power states for.
#         perseus_insts = [
#             list(filter(instruction_map.get, rank_info.pipe_schedule))
#             for rank_info in self.rank_infos
#         ]
#         reported_num_insts = sum(len(insts) for insts in perseus_insts)
#
#         # Any config that is strictly slower than a config that exceeded the deadline
#         # has no chance of observing the deadline. We keep such failed configs here.
#         failed_configs: list[tuple[int]] = []
#
#         def is_slower(config: tuple[int], failed_configs: list[tuple[int]]) -> bool:
#             """Determine whether `config` is slower than one of the failed ones."""
#             for failed_config in reversed(failed_configs):
#                 if all(ps <= failed_ps for ps, failed_ps in zip(config, failed_config)):
#                     return True
#             return False
#
#         # Pipeline schedule as defined by each rank.
#         def schedule_generator(
#             config: list[list[int]],
#         ) -> Callable[[int, int, int], Iterable[rene.Instruction]]:
#             """Return a function that returns the pipeline schedule that Rene can understand.
#
#             `list[rene.Instruction]` will be returned, and each `Instruction` will have their
#             `duration` set to `self._time[power_state]`.
#             """
#
#             def schedule(
#                 num_stages: int,
#                 num_micro_batches: int,
#                 stage_id: int,
#             ) -> Iterable[rene.Instruction]:
#                 # Sanity checks.
#                 assert (
#                     num_stages * len(instruction_map) * num_micro_batches
#                     == reported_num_insts
#                 ), "Inconsistency in pipeline configuration."
#
#                 # Generate Rene instructions and assign durations to each of them
#                 # based on power state allocations.
#                 microbatch_id_counter = {inst: 0 for inst in instruction_map.values()}
#                 rene_insts = []
#                 for perseus_inst, power_state in zip(
#                     perseus_insts[stage_id], config[stage_id]
#                 ):
#                     if (rene_inst_type := instruction_map.get(perseus_inst)) is None:
#                         continue
#                     rene_inst = rene_inst_type(
#                         stage_id=stage_id,
#                         micro_batch_id=microbatch_id_counter[rene_inst_type],
#                         duration=self._inst_time[stage_id][perseus_inst][power_state],
#                     )
#                     microbatch_id_counter[rene_inst_type] += 1
#                     rene_insts.append(rene_inst)
#                 return rene_insts
#
#             return schedule
#
#         def compute_time(config: list[list[int]]) -> float:
#             """Compute the total execution time given the power state config."""
#             dag = rene.InstructionDAG(
#                 schedule_type=schedule_generator(config),
#                 num_stages=self.job_info.pp_degree,
#                 num_micro_batches=self.job_info.num_microbatches,
#                 durations=None,
#             )
#             dag.schedule("eager")
#             return dag.total_execution_time
#
#         def compute_energy(config: list[list[int]]) -> float:
#             """Compute the total execution energy given the power state config."""
#             return sum(
#                 self._inst_energy[stage_id][perseus_inst][power_state]
#                 for stage_id in range(self.job_info.pp_degree)
#                 for perseus_inst, power_state in zip(
#                     perseus_insts[stage_id], config[stage_id]
#                 )
#             )
#
#         # Execute everything with the maximum frequency to figure out our deadline.
#         max_ps = max(self.power_states)
#         max_ps_config: list[list[int]] = (
#             np.array(tuple(max_ps for _ in range(reported_num_insts)))
#             .reshape(self.job_info.pp_degree, -1)
#             .tolist()
#         )
#         deadline = compute_time(max_ps_config) * (1 + self.allowed_slowdown * 0.01)
#
#         # Run through all possible power state configs.
#         pruned_configs = 0
#         # `best_time` is not the best name. It's the estimated time of the min-energy config.
#         best_time, best_energy, best_config = float("inf"), float("inf"), max_ps_config
#
#         for flat_config in product(
#             *[self.power_states for _ in range(reported_num_insts)]
#         ):
#             # `product` doesn't know that all the values it sees will be integers.
#             flat_config = cast(tuple[int], flat_config)
#
#             # If this config is slower than one that failed, don't even try.
#             if self.prune_slower and is_slower(flat_config, failed_configs):
#                 pruned_configs += 1
#                 continue
#
#             # Unflatten from shape [reported_num_insts] to [num_stages, num_insts_per_stage]
#             config: list[list[int]] = (
#                 np.array(flat_config).reshape(self.job_info.pp_degree, -1).tolist()
#             )
#
#             # Compute how long this power state config will take.
#             curr_time = compute_time(config)
#             if curr_time > deadline:
#                 failed_configs.append(flat_config)
#                 continue
#
#             # This power state config can meet the deadline. Compute its total energy.
#             curr_energy = compute_energy(config)
#             if best_energy >= curr_energy:
#                 best_time, best_energy, best_config = curr_time, curr_energy, config
#                 logger.debug(
#                     "Best config updated to %s (time=%s, energy=%s)",
#                     best_config,
#                     best_time,
#                     best_energy,
#                 )
#
#         # Report the effectiveness of pruning.
#         if self.prune_slower:
#             total_configs = len(self.power_states) ** reported_num_insts
#             logger.info(
#                 "%s configs pruned out of %s configs.", pruned_configs, total_configs
#             )
#
#         # Package and return the best config.
#         return best_config


# class AllMaxWithLow(FrequencyScheduler):
#     """Run minimum frequency for LOW and maximum for everything else."""
#
#     def __init__(self, rank_infos: list[RankInfo]) -> None:
#         """Initialize the scheduler."""
#         super().__init__(rank_infos)
#         self.max_freq = max(self.power_state_range)
#         self.min_freq = min(self.power_state_range)
#
#     def observe(self, _: list[ProfilingResult]) -> None:
#         """Observe nothing."""
#
#     def next_schedule(self) -> list[PowerStateSchedule]:
#         """Return the next schedules for all ranks in order."""
#         schedules = []
#         for rank_info in self.rank_infos:
#             schedule = PowerStateSchedule(
#                 power_states=list(
#                     map(
#                         lambda inst: self.min_freq
#                         if inst is PipeInstruction.LOW
#                         else self.max_freq,
#                         rank_info.pipe_schedule,
#                     )
#                 )
#             )
#             schedules.append(schedule)
#         return schedules
#
#
# class AllMaxWithLowTunable(FrequencyScheduler):
#     """Run minimum frequency for LOW and maximum for everything else."""
#
#     def __init__(self, rank_infos: list[RankInfo], low_freq_percent: float) -> None:
#         """Initialize the scheduler."""
#         super().__init__(rank_infos)
#         self.low_freq_percent = low_freq_percent
#         self.max_freq = max(self.power_state_range)
#         num_freqs = len(self.power_state_range)
#         self.low_freq = self.power_state_range[int(num_freqs * low_freq_percent)]
#
#     def observe(self, _: list[ProfilingResult]) -> None:
#         """Observe nothing."""
#
#     def next_schedule(self) -> list[PowerStateSchedule]:
#         """Return the next schedules for all ranks in order."""
#         schedules = []
#         for rank_info in self.rank_infos:
#             schedule = PowerStateSchedule(
#                 power_states=list(
#                     map(
#                         lambda inst: self.low_freq
#                         if inst is PipeInstruction.LOW
#                         else self.max_freq,
#                         rank_info.pipe_schedule,
#                     )
#                 )
#             )
#             schedules.append(schedule)
#         return schedules
#
#
# class AllMaxAutotuneLow(FrequencyScheduler):
#     """Run minimum frequency for LOW and maximum for everything else."""
#
#     def __init__(self, rank_infos: list[RankInfo]) -> None:
#         """Initialize the scheduler."""
#         super().__init__(rank_infos)
#         self.max_freq = max(self.power_state_range)
#         self.low_freq_index = len(self.power_state_range)
#         self.results: dict[int, list[dict]] = {}
#
#     def observe(self, profiling_results: list[ProfilingResult]) -> None:
#         """Observe profiling results."""
#         low_freq = self.power_state_range[self.low_freq_index]
#         logger.debug("%d MHz -> \n%s", low_freq, pformat(profiling_results))
#         self.results[low_freq] = list(map(lambda r: r.dict(), profiling_results))
#
#         if len(self.results) == len(self.power_state_range):
#             with open("AllMaxAutotuneLow.json", "w", encoding="utf-8") as f:
#                 json.dump(self.results, f)
#
#     def next_schedule(self) -> list[PowerStateSchedule]:
#         """Return the next schedules for all ranks in order."""
#         self.low_freq_index = max(self.low_freq_index - 1, 0)
#
#         schedules = []
#         low_freq = self.power_state_range[self.low_freq_index]
#         for rank_info in self.rank_infos:
#             schedule = PowerStateSchedule(
#                 power_states=list(
#                     map(
#                         lambda inst: low_freq
#                         if inst is PipeInstruction.LOW
#                         else self.max_freq,
#                         rank_info.pipe_schedule,
#                     )
#                 )
#             )
#             schedules.append(schedule)
#         return schedules
